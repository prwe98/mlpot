#!/usr/bin/env python3
"""
OUTCARæ•°æ®æ•´åˆå·¥å…·
ä¸“é—¨ç”¨äºå¤„ç†å¤šä¸ªVASP OUTCARæ–‡ä»¶å¹¶æ•´åˆåˆ°mlpotæ¡†æ¶ä¸­
"""

import os
import re
import torch
import numpy as np
import pickle
import h5py
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
import warnings

try:
    from ase.io import read
    from ase import Atoms
    ASE_AVAILABLE = True
except ImportError:
    ASE_AVAILABLE = False
    warnings.warn("ASE not available. Limited functionality for structure processing.")


@dataclass
class OUTCARFrame:
    """å•ä¸ªOUTCARå¸§çš„æ•°æ®ç»“æ„"""
    positions: np.ndarray      # åŸå­ä½ç½® (N, 3)
    atomic_numbers: np.ndarray # åŸå­åºæ•° (N,)
    forces: np.ndarray         # åŸå­åŠ› (N, 3)
    energy: float              # æ€»èƒ½é‡
    cell: Optional[np.ndarray] = None  # æ™¶èƒ (3, 3)
    stress: Optional[np.ndarray] = None  # åº”åŠ›å¼ é‡ (3, 3)
    step: int = 0              # æ­¥æ•°
    source_file: str = ""      # æ¥æºæ–‡ä»¶


class OUTCARParser:
    """OUTCARæ–‡ä»¶è§£æå™¨"""
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
        
    def parse_outcar(self, outcar_path: str) -> List[OUTCARFrame]:
        """
        è§£æå•ä¸ªOUTCARæ–‡ä»¶
        
        Args:
            outcar_path: OUTCARæ–‡ä»¶è·¯å¾„
            
        Returns:
            List[OUTCARFrame]: è§£æçš„å¸§åˆ—è¡¨
        """
        if not os.path.exists(outcar_path):
            raise FileNotFoundError(f"OUTCAR file not found: {outcar_path}")
            
        frames = []
        
        if ASE_AVAILABLE:
            frames = self._parse_with_ase(outcar_path)
        else:
            frames = self._parse_manual(outcar_path)
            
        if self.verbose:
            print(f"âœ… è§£æ {outcar_path}: æ‰¾åˆ° {len(frames)} å¸§")
            
        return frames
    
    def _parse_with_ase(self, outcar_path: str) -> List[OUTCARFrame]:
        """ä½¿ç”¨ASEè§£æOUTCAR"""
        try:
            # è¯»å–æ‰€æœ‰ç»“æ„
            structures = read(outcar_path, index=':', format='vasp-out')
            if not isinstance(structures, list):
                structures = [structures]
                
            frames = []
            for i, atoms in enumerate(structures):
                # æå–åŸºæœ¬ä¿¡æ¯
                positions = atoms.get_positions()
                atomic_numbers = atoms.get_atomic_numbers()
                
                # æå–èƒ½é‡
                energy = atoms.get_potential_energy() if atoms.calc else 0.0
                
                # æå–åŠ›
                try:
                    forces = atoms.get_forces()
                except:
                    forces = np.zeros_like(positions)
                    
                # æå–æ™¶èƒ
                cell = atoms.get_cell() if atoms.pbc.any() else None
                
                frame = OUTCARFrame(
                    positions=positions,
                    atomic_numbers=atomic_numbers,
                    forces=forces,
                    energy=energy,
                    cell=np.array(cell) if cell is not None else None,
                    step=i,
                    source_file=outcar_path
                )
                frames.append(frame)
                
            return frames
            
        except Exception as e:
            warnings.warn(f"ASE parsing failed for {outcar_path}: {e}")
            return self._parse_manual(outcar_path)
    
    def _parse_manual(self, outcar_path: str) -> List[OUTCARFrame]:
        """æ‰‹åŠ¨è§£æOUTCARï¼ˆä¸ä¾èµ–ASEï¼‰"""
        frames = []
        
        with open(outcar_path, 'r') as f:
            content = f.read()
            
        # è§£æåŸå­ä¿¡æ¯ï¼ˆä»ç¬¬ä¸€ä¸ªç¦»å­ä½ç½®å—è·å–ï¼‰
        atomic_numbers = self._extract_atomic_numbers(content)
        
        # æå–æ‰€æœ‰çš„èƒ½é‡å’ŒåŠ›ä¿¡æ¯
        energies = self._extract_energies(content)
        positions_list = self._extract_positions(content)
        forces_list = self._extract_forces(content)
        cells = self._extract_cells(content)
        
        # ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
        min_length = min(len(energies), len(positions_list), len(forces_list))
        
        for i in range(min_length):
            frame = OUTCARFrame(
                positions=positions_list[i],
                atomic_numbers=atomic_numbers,
                forces=forces_list[i],
                energy=energies[i],
                cell=cells[0] if cells else None,  # é€šå¸¸æ™¶èƒä¸å˜
                step=i,
                source_file=outcar_path
            )
            frames.append(frame)
            
        return frames
    
    def _extract_atomic_numbers(self, content: str) -> np.ndarray:
        """æå–åŸå­åºæ•°"""
        # æŸ¥æ‰¾POTCARä¿¡æ¯æ¥ç¡®å®šåŸå­ç±»å‹
        element_pattern = r'VRHFIN =(\w+)'
        elements = re.findall(element_pattern, content)
        
        # æŸ¥æ‰¾æ¯ç§åŸå­çš„æ•°é‡
        ions_per_type_pattern = r'ions per type =\s*([\d\s]+)'
        ions_match = re.search(ions_per_type_pattern, content)
        
        if not ions_match or not elements:
            raise ValueError("æ— æ³•è§£æåŸå­ä¿¡æ¯")
            
        ions_per_type = list(map(int, ions_match.group(1).split()))
        
        # å…ƒç´ ç¬¦å·åˆ°åŸå­åºæ•°çš„æ˜ å°„
        element_to_z = {
            'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8,
            'F': 9, 'Ne': 10, 'Na': 11, 'Mg': 12, 'Al': 13, 'Si': 14, 'P': 15,
            'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20, 'Sc': 21, 'Ti': 22,
            'V': 23, 'Cr': 24, 'Mn': 25, 'Fe': 26, 'Co': 27, 'Ni': 28, 'Cu': 29,
            'Zn': 30, 'Ga': 31, 'Ge': 32, 'As': 33, 'Se': 34, 'Br': 35, 'Kr': 36
        }
        
        atomic_numbers = []
        for element, count in zip(elements, ions_per_type):
            if element in element_to_z:
                atomic_numbers.extend([element_to_z[element]] * count)
            else:
                # å¦‚æœå…ƒç´ ä¸åœ¨æ˜ å°„ä¸­ï¼Œå°è¯•ä»å…ƒç´ ç¬¦å·æå–
                z = self._symbol_to_atomic_number(element)
                atomic_numbers.extend([z] * count)
                
        return np.array(atomic_numbers)
    
    def _symbol_to_atomic_number(self, symbol: str) -> int:
        """å°†å…ƒç´ ç¬¦å·è½¬æ¢ä¸ºåŸå­åºæ•°"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼Œæ‚¨å¯ä»¥æ‰©å±•è¿™ä¸ªæ˜ å°„
        basic_map = {
            'H': 1, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Si': 14, 'P': 15, 'S': 16,
            'Cl': 17, 'Fe': 26, 'Ni': 28, 'Cu': 29, 'Zn': 30, 'Br': 35
        }
        return basic_map.get(symbol, 6)  # é»˜è®¤è¿”å›ç¢³
    
    def _extract_energies(self, content: str) -> List[float]:
        """æå–èƒ½é‡"""
        # æŸ¥æ‰¾ "free energy" æˆ– "energy without entropy"
        energy_pattern = r'free\s+energy\s+TOTEN\s*=\s*([-\d\.]+)'
        energies = re.findall(energy_pattern, content)
        return [float(e) for e in energies]
    
    def _extract_positions(self, content: str) -> List[np.ndarray]:
        """æå–åŸå­ä½ç½®"""
        positions_list = []
        
        # æŸ¥æ‰¾æ‰€æœ‰çš„ä½ç½®å—
        position_blocks = re.findall(
            r'POSITION\s+TOTAL-FORCE \(eV/Angst\)\s*\n\s*-+\s*\n(.*?)(?=\n\s*-+|\Z)',
            content, re.DOTALL
        )
        
        for block in position_blocks:
            positions = []
            lines = block.strip().split('\n')
            for line in lines:
                if line.strip():
                    parts = line.split()
                    if len(parts) >= 6:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„åˆ—
                        try:
                            pos = [float(parts[0]), float(parts[1]), float(parts[2])]
                            positions.append(pos)
                        except ValueError:
                            continue
            if positions:
                positions_list.append(np.array(positions))
                
        return positions_list
    
    def _extract_forces(self, content: str) -> List[np.ndarray]:
        """æå–åŠ›"""
        forces_list = []
        
        # æŸ¥æ‰¾æ‰€æœ‰çš„åŠ›å—
        position_blocks = re.findall(
            r'POSITION\s+TOTAL-FORCE \(eV/Angst\)\s*\n\s*-+\s*\n(.*?)(?=\n\s*-+|\Z)',
            content, re.DOTALL
        )
        
        for block in position_blocks:
            forces = []
            lines = block.strip().split('\n')
            for line in lines:
                if line.strip():
                    parts = line.split()
                    if len(parts) >= 6:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„åˆ—
                        try:
                            force = [float(parts[3]), float(parts[4]), float(parts[5])]
                            forces.append(force)
                        except ValueError:
                            continue
            if forces:
                forces_list.append(np.array(forces))
                
        return forces_list
    
    def _extract_cells(self, content: str) -> List[np.ndarray]:
        """æå–æ™¶èƒå‚æ•°"""
        cells = []
        
        # æŸ¥æ‰¾æ™¶æ ¼å‘é‡
        cell_pattern = r'direct lattice vectors\s+reciprocal lattice vectors\s*\n(.*?)\n.*?\n.*?\n'
        cell_matches = re.findall(cell_pattern, content, re.DOTALL)
        
        for match in cell_matches:
            lines = match.strip().split('\n')
            if len(lines) >= 3:
                cell = []
                for i in range(3):
                    parts = lines[i].split()
                    if len(parts) >= 3:
                        cell.append([float(parts[0]), float(parts[1]), float(parts[2])])
                if len(cell) == 3:
                    cells.append(np.array(cell))
                    
        return cells


class OUTCARDatasetBuilder:
    """OUTCARæ•°æ®é›†æ„å»ºå™¨"""
    
    def __init__(self, output_format: str = 'h5', verbose: bool = True):
        """
        Args:
            output_format: è¾“å‡ºæ ¼å¼ ('h5', 'pickle', 'npz')
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        """
        self.output_format = output_format
        self.verbose = verbose
        self.parser = OUTCARParser(verbose=verbose)
        
    def build_dataset(
        self,
        outcar_paths: List[str],
        output_path: str,
        energy_unit: str = 'eV',
        force_unit: str = 'eV/Angst',
        position_unit: str = 'Angst'
    ) -> Dict[str, Any]:
        """
        æ„å»ºæ•°æ®é›†
        
        Args:
            outcar_paths: OUTCARæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            energy_unit: èƒ½é‡å•ä½
            force_unit: åŠ›çš„å•ä½
            position_unit: ä½ç½®å•ä½
            
        Returns:
            Dict: æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        """
        all_frames = []
        
        # è§£ææ‰€æœ‰OUTCARæ–‡ä»¶
        if self.verbose:
            print(f"ğŸ”„ å¼€å§‹è§£æ {len(outcar_paths)} ä¸ªOUTCARæ–‡ä»¶...")
            
        for outcar_path in outcar_paths:
            try:
                frames = self.parser.parse_outcar(outcar_path)
                all_frames.extend(frames)
            except Exception as e:
                warnings.warn(f"è§£ææ–‡ä»¶å¤±è´¥ {outcar_path}: {e}")
                continue
                
        if not all_frames:
            raise ValueError("æ²¡æœ‰æˆåŠŸè§£æä»»ä½•OUTCARæ–‡ä»¶")
            
        if self.verbose:
            print(f"âœ… æ€»å…±è§£æäº† {len(all_frames)} ä¸ªç»“æ„")
            
        # è½¬æ¢ä¸ºmlpotæ ¼å¼
        dataset = self._convert_to_mlpot_format(all_frames)
        
        # ä¿å­˜æ•°æ®é›†
        self._save_dataset(dataset, output_path)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        stats = self._compute_statistics(dataset)
        
        if self.verbose:
            self._print_statistics(stats)
            
        return stats
    
    def _convert_to_mlpot_format(self, frames: List[OUTCARFrame]) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºmlpotæ ¼å¼"""
        dataset = {
            'positions': [],
            'atomic_numbers': [],
            'forces': [],
            'energies': [],
            'cells': [],
            'num_atoms': [],
            'metadata': {
                'total_frames': len(frames),
                'source': 'OUTCAR',
                'units': {
                    'energy': 'eV',
                    'force': 'eV/Angst',
                    'position': 'Angst'
                }
            }
        }
        
        for frame in frames:
            dataset['positions'].append(frame.positions)
            dataset['atomic_numbers'].append(frame.atomic_numbers)
            dataset['forces'].append(frame.forces)
            dataset['energies'].append(frame.energy)
            dataset['num_atoms'].append(len(frame.atomic_numbers))
            
            if frame.cell is not None:
                dataset['cells'].append(frame.cell)
            else:
                # å¯¹äºéå‘¨æœŸæ€§ç³»ç»Ÿï¼Œåˆ›å»ºä¸€ä¸ªå¤§çš„å•ä½æ™¶èƒ
                large_cell = np.eye(3) * 100.0
                dataset['cells'].append(large_cell)
                
        return dataset
    
    def _save_dataset(self, dataset: Dict[str, Any], output_path: str):
        """ä¿å­˜æ•°æ®é›†"""
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        if self.output_format == 'h5':
            self._save_h5(dataset, str(output_path))
        elif self.output_format == 'pickle':
            self._save_pickle(dataset, str(output_path))
        elif self.output_format == 'npz':
            self._save_npz(dataset, str(output_path))
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¾“å‡ºæ ¼å¼: {self.output_format}")
            
        if self.verbose:
            print(f"ğŸ’¾ æ•°æ®é›†å·²ä¿å­˜åˆ°: {output_path}")
    
    def _save_h5(self, dataset: Dict[str, Any], output_path: str):
        """ä¿å­˜ä¸ºHDF5æ ¼å¼"""
        with h5py.File(output_path, 'w') as f:
            # ä¿å­˜æ•°ç»„æ•°æ®
            for key in ['positions', 'atomic_numbers', 'forces', 'energies', 'cells', 'num_atoms']:
                if key in dataset:
                    f.create_dataset(key, data=dataset[key])
            
            # ä¿å­˜å…ƒæ•°æ®
            meta_group = f.create_group('metadata')
            for key, value in dataset['metadata'].items():
                if isinstance(value, dict):
                    sub_group = meta_group.create_group(key)
                    for sub_key, sub_value in value.items():
                        sub_group.attrs[sub_key] = sub_value
                else:
                    meta_group.attrs[key] = value
    
    def _save_pickle(self, dataset: Dict[str, Any], output_path: str):
        """ä¿å­˜ä¸ºPickleæ ¼å¼"""
        with open(output_path, 'wb') as f:
            pickle.dump(dataset, f)
    
    def _save_npz(self, dataset: Dict[str, Any], output_path: str):
        """ä¿å­˜ä¸ºNPZæ ¼å¼"""
        np.savez_compressed(output_path, **dataset)
    
    def _compute_statistics(self, dataset: Dict[str, Any]) -> Dict[str, float]:
        """è®¡ç®—æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        energies = np.array(dataset['energies'])
        forces = np.concatenate(dataset['forces'])
        num_atoms = np.array(dataset['num_atoms'])
        
        stats = {
            'total_structures': len(dataset['energies']),
            'total_atoms': np.sum(num_atoms),
            'avg_atoms_per_structure': np.mean(num_atoms),
            'energy_mean': np.mean(energies),
            'energy_std': np.std(energies),
            'energy_min': np.min(energies),
            'energy_max': np.max(energies),
            'force_mean': np.mean(np.abs(forces)),
            'force_std': np.std(forces),
            'force_max': np.max(np.abs(forces))
        }
        
        return stats
    
    def _print_statistics(self, stats: Dict[str, float]):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯:")
        print("=" * 50)
        print(f"æ€»ç»“æ„æ•°: {stats['total_structures']}")
        print(f"æ€»åŸå­æ•°: {stats['total_atoms']}")
        print(f"å¹³å‡æ¯ç»“æ„åŸå­æ•°: {stats['avg_atoms_per_structure']:.1f}")
        print(f"èƒ½é‡èŒƒå›´: {stats['energy_min']:.3f} ~ {stats['energy_max']:.3f} eV")
        print(f"èƒ½é‡å‡å€¼: {stats['energy_mean']:.3f} Â± {stats['energy_std']:.3f} eV")
        print(f"åŠ›å‡å€¼(ç»å¯¹å€¼): {stats['force_mean']:.3f} eV/Ã…")
        print(f"åŠ›æ ‡å‡†å·®: {stats['force_std']:.3f} eV/Ã…")
        print(f"æœ€å¤§åŠ›: {stats['force_max']:.3f} eV/Ã…")


def find_outcar_files(root_dir: str, recursive: bool = True) -> List[str]:
    """
    åœ¨ç›®å½•ä¸­æŸ¥æ‰¾æ‰€æœ‰OUTCARæ–‡ä»¶
    
    Args:
        root_dir: æ ¹ç›®å½•
        recursive: æ˜¯å¦é€’å½’æœç´¢
        
    Returns:
        List[str]: OUTCARæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    outcar_files = []
    root_path = Path(root_dir)
    
    if recursive:
        # é€’å½’æœç´¢
        for outcar_file in root_path.rglob("OUTCAR*"):
            if outcar_file.is_file():
                outcar_files.append(str(outcar_file))
    else:
        # åªæœç´¢å½“å‰ç›®å½•
        for outcar_file in root_path.glob("OUTCAR*"):
            if outcar_file.is_file():
                outcar_files.append(str(outcar_file))
                
    return sorted(outcar_files)


def main():
    """ç¤ºä¾‹ä½¿ç”¨"""
    import argparse
    
    parser = argparse.ArgumentParser(description="OUTCARæ•°æ®æ•´åˆå·¥å…·")
    parser.add_argument("--input_dir", "-i", type=str, required=True,
                       help="åŒ…å«OUTCARæ–‡ä»¶çš„ç›®å½•")
    parser.add_argument("--output", "-o", type=str, default="outcar_dataset.h5",
                       help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--format", "-f", type=str, default="h5",
                       choices=['h5', 'pickle', 'npz'],
                       help="è¾“å‡ºæ ¼å¼")
    parser.add_argument("--recursive", "-r", action="store_true",
                       help="é€’å½’æœç´¢OUTCARæ–‡ä»¶")
    parser.add_argument("--files", nargs="+", type=str,
                       help="æŒ‡å®šç‰¹å®šçš„OUTCARæ–‡ä»¶")
    
    args = parser.parse_args()
    
    # æŸ¥æ‰¾OUTCARæ–‡ä»¶
    if args.files:
        outcar_files = args.files
    else:
        outcar_files = find_outcar_files(args.input_dir, args.recursive)
    
    if not outcar_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°OUTCARæ–‡ä»¶")
        return
    
    print(f"ğŸ” æ‰¾åˆ° {len(outcar_files)} ä¸ªOUTCARæ–‡ä»¶")
    for f in outcar_files:
        print(f"  - {f}")
    
    # æ„å»ºæ•°æ®é›†
    builder = OUTCARDatasetBuilder(output_format=args.format)
    try:
        stats = builder.build_dataset(outcar_files, args.output)
        print(f"\nğŸ‰ æ•°æ®é›†æ„å»ºå®Œæˆ!")
        print(f"è¾“å‡ºæ–‡ä»¶: {args.output}")
    except Exception as e:
        print(f"âŒ æ„å»ºå¤±è´¥: {e}")


if __name__ == "__main__":
    main()
