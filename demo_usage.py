#!/usr/bin/env python3
"""
mlpotä½¿ç”¨ç¤ºä¾‹ï¼šå®Œæ•´çš„åˆ†å­åŠ¿èƒ½å­¦ä¹ æµç¨‹
è¿™ä¸ªç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨mlpotæ¡†æ¶è¿›è¡Œåˆ†å­åŠ¿èƒ½é¢„æµ‹
"""

import sys
import os
import torch
import torch.nn as nn
import numpy as np
from typing import Dict, Tuple
import matplotlib.pyplot as plt

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def create_demo_dataset():
    """åˆ›å»ºæ¼”ç¤ºæ•°æ®é›†"""
    print("ğŸ“¦ åˆ›å»ºæ¼”ç¤ºæ•°æ®é›†...")
    
    # åˆ›å»ºä¸€äº›ç®€å•çš„åˆ†å­ç»“æ„
    molecules = []
    
    # åˆ†å­1: H2O (æ°´åˆ†å­)
    h2o = {
        'pos': torch.tensor([
            [0.0, 0.0, 0.0],      # O
            [0.76, 0.59, 0.0],    # H1
            [-0.76, 0.59, 0.0]    # H2
        ]),
        'atomic_numbers': torch.tensor([8, 1, 1]),  # O, H, H
        'energy': torch.tensor(-76.3),  # å‡è®¾èƒ½é‡
        'forces': torch.tensor([
            [0.0, 0.0, 0.0],
            [0.1, -0.1, 0.0],
            [-0.1, -0.1, 0.0]
        ])
    }
    
    # åˆ†å­2: CH4 (ç”²çƒ·)
    ch4 = {
        'pos': torch.tensor([
            [0.0, 0.0, 0.0],      # C
            [1.09, 1.09, 1.09],   # H1
            [-1.09, -1.09, 1.09], # H2
            [-1.09, 1.09, -1.09], # H3
            [1.09, -1.09, -1.09]  # H4
        ]),
        'atomic_numbers': torch.tensor([6, 1, 1, 1, 1]),  # C, H, H, H, H
        'energy': torch.tensor(-40.5),  # å‡è®¾èƒ½é‡
        'forces': torch.tensor([
            [0.0, 0.0, 0.0],
            [0.05, 0.05, 0.05],
            [-0.05, -0.05, 0.05],
            [-0.05, 0.05, -0.05],
            [0.05, -0.05, -0.05]
        ])
    }
    
    molecules = [h2o, ch4]
    
    # åˆ›å»ºæ‰¹å¤„ç†æ•°æ®
    all_pos = []
    all_atomic_numbers = []
    all_energies = []
    all_forces = []
    batch_indices = []
    
    for mol_idx, mol in enumerate(molecules):
        all_pos.append(mol['pos'])
        all_atomic_numbers.append(mol['atomic_numbers'])
        all_energies.append(mol['energy'])
        all_forces.append(mol['forces'])
        
        # æ‰¹ç´¢å¼•
        batch_indices.extend([mol_idx] * len(mol['atomic_numbers']))
    
    batch_data = {
        'pos': torch.cat(all_pos, dim=0),
        'atomic_numbers': torch.cat(all_atomic_numbers, dim=0),
        'batch': torch.tensor(batch_indices),
        'energy': torch.stack(all_energies),
        'forces': torch.cat(all_forces, dim=0)
    }
    
    print(f"âœ… åˆ›å»ºäº†åŒ…å« {len(molecules)} ä¸ªåˆ†å­çš„æ•°æ®é›†")
    return batch_data

def create_mlpot_model():
    """åˆ›å»ºmlpotæ¨¡å‹"""
    print("\nğŸ—ï¸  åˆ›å»ºmlpotæ¨¡å‹...")
    
    try:
        # å¯¼å…¥æ‰€éœ€æ¨¡å—
        import importlib.util
        
        spec = importlib.util.spec_from_file_location("base_model", "core/base_model.py")
        base_model = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(base_model)
        
        spec = importlib.util.spec_from_file_location("geometric_layers", "layers/geometric_layers.py")
        geom_layers = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(geom_layers)
        
        # åˆ›å»ºå®Œæ•´çš„mlpotæ¨¡å‹
        class MLPotModel(base_model.BasePotential):
            def __init__(self, hidden_dim=128, num_layers=3):
                super().__init__()
                self.hidden_dim = hidden_dim
                self.num_layers = num_layers
                
                # åŸå­åµŒå…¥
                self.atomic_embedding = geom_layers.AtomicEmbedding(hidden_dim, 84)
                
                # å¾„å‘åŸºå‡½æ•°
                self.radial_basis = geom_layers.RadialBasisFunction(
                    num_radial=64, cutoff=5.0
                )
                
                # æ¶ˆæ¯ä¼ é€’å±‚
                self.message_layers = nn.ModuleList()
                for _ in range(num_layers):
                    self.message_layers.append(
                        nn.Sequential(
                            nn.Linear(hidden_dim, hidden_dim),
                            geom_layers.ScaledActivation(),
                            nn.Linear(hidden_dim, hidden_dim)
                        )
                    )
                
                # è¾“å‡ºå±‚
                self.energy_head = nn.Sequential(
                    nn.Linear(hidden_dim, hidden_dim // 2),
                    geom_layers.ScaledActivation(),
                    nn.Linear(hidden_dim // 2, 1)
                )
                
                self.force_head = nn.Linear(hidden_dim, 3)
                
            def forward(self, data):
                atomic_numbers = data['atomic_numbers'].long()
                pos = data['pos']
                batch = data['batch']
                
                # åµŒå…¥åŸå­ç‰¹å¾
                node_features = self.atomic_embedding(atomic_numbers)
                
                # ç®€å•çš„å›¾å·ç§¯ï¼ˆæ¼”ç¤ºç”¨ï¼‰
                for layer in self.message_layers:
                    node_features = layer(node_features) + node_features
                
                # é¢„æµ‹èƒ½é‡
                per_atom_energy = self.energy_head(node_features).squeeze(1)
                from torch_scatter import scatter
                total_energy = scatter(per_atom_energy, batch, dim=0, reduce='sum')
                
                # é¢„æµ‹åŠ›
                forces = self.force_head(node_features)
                
                return total_energy, forces
            
            def get_energy_and_forces(self, data):
                return self.forward(data)
        
        model = MLPotModel()
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
        return model
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return None

def train_model_demo(model, data):
    """æ¼”ç¤ºæ¨¡å‹è®­ç»ƒ"""
    print("\nğŸ‹ï¸ æ¼”ç¤ºæ¨¡å‹è®­ç»ƒ...")
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    
    # è®­ç»ƒå¾ªç¯
    num_epochs = 2000
    losses = []
    
    for epoch in range(num_epochs):
        optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        pred_energy, pred_forces = model(data)
        
        # è®¡ç®—æŸå¤±
        energy_loss = nn.MSELoss()(pred_energy, data['energy'])
        force_loss = nn.MSELoss()(pred_forces, data['forces'])
        total_loss = energy_loss + 10 * force_loss  # åŠ›æŸå¤±æƒé‡æ›´é«˜
        
        # åå‘ä¼ æ’­
        total_loss.backward()
        optimizer.step()
        
        losses.append(total_loss.item())
        
        if epoch % 5 == 0:
            print(f"  Epoch {epoch:2d}: æŸå¤± = {total_loss.item():.6f}")
    
    print(f"âœ… è®­ç»ƒå®Œæˆï¼Œæœ€ç»ˆæŸå¤±: {losses[-1]:.6f}")
    return losses

def evaluate_model(model, data):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    print("\nğŸ“Š è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    
    with torch.no_grad():
        pred_energy, pred_forces = model(data)
    
    # è®¡ç®—è¯¯å·®
    energy_mae = torch.mean(torch.abs(pred_energy - data['energy']))
    force_mae = torch.mean(torch.abs(pred_forces - data['forces']))
    
    print(f"âœ… è¯„ä¼°ç»“æœ:")
    print(f"   èƒ½é‡å¹³å‡ç»å¯¹è¯¯å·®: {energy_mae.item():.6f} eV")
    print(f"   åŠ›å¹³å‡ç»å¯¹è¯¯å·®: {force_mae.item():.6f} eV/Ã…")
    
    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    print(f"\nğŸ” è¯¦ç»†é¢„æµ‹ç»“æœ:")
    for i in range(len(data['energy'])):
        print(f"   åˆ†å­ {i+1}:")
        print(f"     çœŸå®èƒ½é‡: {data['energy'][i].item():.3f} eV")
        print(f"     é¢„æµ‹èƒ½é‡: {pred_energy[i].item():.3f} eV")
    
    return pred_energy, pred_forces

def visualize_results(losses):
    """å¯è§†åŒ–è®­ç»ƒç»“æœ"""
    print("\nğŸ“ˆ ç”Ÿæˆè®­ç»ƒæ›²çº¿...")
    
    try:
        plt.figure(figsize=(10, 6))
        plt.plot(losses, 'b-', linewidth=2)
        plt.xlabel('Training Epoch')
        plt.ylabel('Loss Value')
        plt.title('MLPot Model Training Curve')
        plt.grid(True, alpha=0.3)
        plt.yscale('log')
        
        # ä¿å­˜å›¾ç‰‡
        plt.savefig('mlpot_training_curve.png', dpi=150, bbox_inches='tight')
        print("âœ… è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ° mlpot_training_curve.png")
        
        # æ˜¾ç¤º
        plt.show()
        
    except Exception as e:
        print(f"âš ï¸  å¯è§†åŒ–å¤±è´¥ (å¯èƒ½ç¼ºå°‘GUI): {e}")

def demonstrate_equivariance(model, data):
    """æ¼”ç¤ºç­‰å˜æ€§è´¨"""
    print("\nğŸ”„ æ¼”ç¤ºç­‰å˜æ€§è´¨...")
    
    # åŸå§‹é¢„æµ‹
    with torch.no_grad():
        original_energy, original_forces = model(data)
    
    # æ—‹è½¬å˜æ¢
    angle = np.pi / 4  # 45åº¦
    rotation_matrix = torch.tensor([
        [np.cos(angle), -np.sin(angle), 0],
        [np.sin(angle), np.cos(angle), 0],
        [0, 0, 1]
    ], dtype=torch.float32)
    
    # å˜æ¢æ•°æ®
    transformed_data = data.copy()
    transformed_data['pos'] = torch.matmul(data['pos'], rotation_matrix.T)
    
    # å˜æ¢åçš„é¢„æµ‹
    with torch.no_grad():
        transformed_energy, transformed_forces = model(transformed_data)
    
    # æ£€æŸ¥èƒ½é‡ä¸å˜æ€§
    energy_diff = torch.abs(original_energy - transformed_energy)
    energy_invariant = torch.all(energy_diff < 1e-3)
    
    print(f"âœ… ç­‰å˜æ€§æ£€æŸ¥:")
    print(f"   èƒ½é‡ä¸å˜æ€§: {'é€šè¿‡' if energy_invariant else 'å¤±è´¥'}")
    print(f"   æœ€å¤§èƒ½é‡å·®å¼‚: {energy_diff.max().item():.6f} eV")

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ mlpotåˆ†å­åŠ¿èƒ½å­¦ä¹ æ¼”ç¤º")
    print("=" * 50)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    # 1. åˆ›å»ºæ•°æ®
    data = create_demo_dataset()
    
    # 2. åˆ›å»ºæ¨¡å‹
    model = create_mlpot_model()
    if model is None:
        return
    
    # 3. è®­ç»ƒæ¨¡å‹
    losses = train_model_demo(model, data)
    
    # 4. è¯„ä¼°æ€§èƒ½
    pred_energy, pred_forces = evaluate_model(model, data)
    
    # 5. å¯è§†åŒ–ç»“æœ
    visualize_results(losses)
    
    # 6. æ¼”ç¤ºç­‰å˜æ€§
    demonstrate_equivariance(model, data)
    
    print("\n" + "=" * 50)
    print("ğŸ‰ mlpotæ¼”ç¤ºå®Œæˆï¼")
    print("\nâœ¨ æ¡†æ¶ç‰¹ç‚¹:")
    print("   ğŸ§  åŸºäºE2GNNçš„ç­‰å˜æ¶æ„")
    print("   ğŸ”§ æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•")
    print("   ğŸ“Š å®Œæ•´çš„è®­ç»ƒå’Œè¯„ä¼°æµç¨‹")
    print("   ğŸ§ª ç­‰å˜æ€§è´¨éªŒè¯")
    print("   ğŸ“ˆ å¯è§†åŒ–å·¥å…·")
    print("\nğŸš€ å‡†å¤‡å¥½ç”¨äºå®é™…çš„åˆ†å­åŠ¿èƒ½å­¦ä¹ ä»»åŠ¡ï¼")

if __name__ == "__main__":
    main()
