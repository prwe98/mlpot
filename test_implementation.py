#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯mlpotå®ç°ä¸E2GNNçš„ä¸€è‡´æ€§
è¿™ä¸ªè„šæœ¬ä¼šæµ‹è¯•æ¨¡å‹çš„åŸºæœ¬åŠŸèƒ½ã€ç­‰å˜æ€§è´¨å’Œæ•°å­¦æ­£ç¡®æ€§
"""

import sys
import os

# æ·»åŠ è·¯å¾„åˆ°sys.pathä¸­
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, current_dir)
sys.path.insert(0, project_root)

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, Tuple
import matplotlib.pyplot as plt

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
try:
    from mlpot.models.equivariant_net import (
        EquivariantNet, 
        EquivariantMessageLayer, 
        EquivariantUpdateLayer,
        GlobalScalarProcessor,
        GlobalVectorProcessor
    )
    from mlpot.layers.geometric_layers import RadialBasisFunction, AtomicEmbedding, ScaledActivation
    from mlpot.data.dataset import MolecularDataset
    from mlpot.utils.metrics import compute_mae, compute_rmse
except ImportError:
    # å¦‚æœä½œä¸ºè„šæœ¬è¿è¡Œï¼Œå°è¯•ç›¸å¯¹å¯¼å…¥
    import importlib.util
    import sys
    
    # æ‰‹åŠ¨å¯¼å…¥æ¨¡å—
    modules_to_import = [
        ('equivariant_net', 'models/equivariant_net.py'),
        ('geometric_layers', 'layers/geometric_layers.py'),
        ('dataset', 'data/dataset.py'),
        ('metrics', 'utils/metrics.py')
    ]
    
    for module_name, module_path in modules_to_import:
        spec = importlib.util.spec_from_file_location(module_name, module_path)
        module = importlib.util.module_from_spec(spec)
        sys.modules[module_name] = module
        spec.loader.exec_module(module)
    
    # å¯¼å…¥éœ€è¦çš„ç±»å’Œå‡½æ•°
    from equivariant_net import (
        EquivariantNet, 
        EquivariantMessageLayer, 
        EquivariantUpdateLayer,
        GlobalScalarProcessor,
        GlobalVectorProcessor
    )
    from geometric_layers import RadialBasisFunction, AtomicEmbedding, ScaledActivation
    from dataset import MolecularDataset
    from metrics import compute_mae, compute_rmse


def create_test_data(num_atoms: int = 5, batch_size: int = 2) -> Dict[str, torch.Tensor]:
    """
    åˆ›å»ºæµ‹è¯•ç”¨çš„åˆ†å­æ•°æ®
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºéšæœºåˆ†å­ç»“æ„
    total_atoms = num_atoms * batch_size
    
    data = {
        'pos': torch.randn(total_atoms, 3, device=device),
        'atomic_numbers': torch.randint(1, 84, (total_atoms,), device=device),
        'batch': torch.repeat_interleave(torch.arange(batch_size, device=device), num_atoms),
        'num_atoms': torch.tensor([num_atoms] * batch_size, device=device)
    }
    
    return data


def test_model_forward():
    """
    æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
    """
    print("ğŸ§ª æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    model = EquivariantNet(
        hidden_dim=64,  # ä½¿ç”¨è¾ƒå°çš„ç»´åº¦æ¥å¿«é€Ÿæµ‹è¯•
        num_layers=2,
        num_radial_basis=32,
        cutoff_radius=5.0,
        max_neighbors=10
    ).to(device)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    data = create_test_data(num_atoms=5, batch_size=2)
    
    # å‰å‘ä¼ æ’­
    try:
        with torch.no_grad():
            energy, forces = model(data)
        
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ!")
        print(f"   èƒ½é‡å½¢çŠ¶: {energy.shape}")
        print(f"   åŠ›çš„å½¢çŠ¶: {forces.shape}")
        print(f"   èƒ½é‡å€¼: {energy.detach().cpu().numpy()}")
        
        return True
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        return False


def test_equivariance():
    """
    æµ‹è¯•æ¨¡å‹çš„ç­‰å˜æ€§è´¨
    """
    print("\nğŸ”„ æµ‹è¯•ç­‰å˜æ€§è´¨...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹
    model = EquivariantNet(
        hidden_dim=64,
        num_layers=2,
        num_radial_basis=32,
        cutoff_radius=5.0,
        max_neighbors=10
    ).to(device)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    data = create_test_data(num_atoms=4, batch_size=1)
    
    # åˆ›å»ºéšæœºæ—‹è½¬çŸ©é˜µ
    angle = np.pi / 4  # 45åº¦
    rotation_matrix = torch.tensor([
        [np.cos(angle), -np.sin(angle), 0],
        [np.sin(angle), np.cos(angle), 0],
        [0, 0, 1]
    ], dtype=torch.float32, device=device)
    
    translation = torch.tensor([1.0, 2.0, 3.0], device=device)
    
    try:
        is_equivariant = model.check_equivariance(data, rotation_matrix, translation)
        
        if is_equivariant:
            print("âœ… ç­‰å˜æ€§æµ‹è¯•é€šè¿‡!")
        else:
            print("âŒ ç­‰å˜æ€§æµ‹è¯•å¤±è´¥!")
            
        return is_equivariant
    except Exception as e:
        print(f"âŒ ç­‰å˜æ€§æµ‹è¯•å‡ºé”™: {e}")
        return False


def test_components():
    """
    æµ‹è¯•å„ä¸ªç»„ä»¶
    """
    print("\nğŸ”§ æµ‹è¯•æ¨¡å‹ç»„ä»¶...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    hidden_dim = 64
    num_radial_basis = 32
    
    # æµ‹è¯•å¾„å‘åŸºå‡½æ•°
    print("  æµ‹è¯•å¾„å‘åŸºå‡½æ•°...")
    rbf = RadialBasisFunction(num_radial=num_radial_basis, cutoff=5.0).to(device)
    distances = torch.linspace(0.5, 5.0, 10, device=device)
    rbf_output = rbf(distances)
    print(f"    RBFè¾“å‡ºå½¢çŠ¶: {rbf_output.shape}")
    
    # æµ‹è¯•åŸå­åµŒå…¥
    print("  æµ‹è¯•åŸå­åµŒå…¥...")
    embedding = AtomicEmbedding(hidden_dim, num_elements=84).to(device)
    atomic_numbers = torch.randint(1, 84, (10,), device=device)
    embed_output = embedding(atomic_numbers)
    print(f"    åµŒå…¥è¾“å‡ºå½¢çŠ¶: {embed_output.shape}")
    
    # æµ‹è¯•ç¼©æ”¾æ¿€æ´»å‡½æ•°
    print("  æµ‹è¯•ç¼©æ”¾æ¿€æ´»å‡½æ•°...")
    activation = ScaledActivation().to(device)
    test_input = torch.randn(5, hidden_dim, device=device)
    activation_output = activation(test_input)
    print(f"    æ¿€æ´»å‡½æ•°è¾“å‡ºå½¢çŠ¶: {activation_output.shape}")
    
    # æµ‹è¯•æ¶ˆæ¯ä¼ é€’å±‚
    print("  æµ‹è¯•æ¶ˆæ¯ä¼ é€’å±‚...")
    message_layer = EquivariantMessageLayer(hidden_dim, num_radial_basis).to(device)
    
    num_nodes = 5
    node_features = torch.randn(num_nodes, hidden_dim, device=device)
    vector_features = torch.randn(num_nodes, 3, hidden_dim, device=device)
    edge_index = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]], device=device)
    edge_radial = torch.randn(4, num_radial_basis, device=device)
    edge_vectors = torch.randn(4, 3, device=device)
    
    scalar_msg, vector_msg = message_layer(
        node_features, vector_features, edge_index, edge_radial, edge_vectors
    )
    print(f"    æ ‡é‡æ¶ˆæ¯å½¢çŠ¶: {scalar_msg.shape}")
    print(f"    å‘é‡æ¶ˆæ¯å½¢çŠ¶: {vector_msg.shape}")
    
    # æµ‹è¯•æ›´æ–°å±‚
    print("  æµ‹è¯•æ›´æ–°å±‚...")
    update_layer = EquivariantUpdateLayer(hidden_dim).to(device)
    scalar_update, vector_update = update_layer(node_features, vector_features)
    print(f"    æ ‡é‡æ›´æ–°å½¢çŠ¶: {scalar_update.shape}")
    print(f"    å‘é‡æ›´æ–°å½¢çŠ¶: {vector_update.shape}")
    
    print("âœ… æ‰€æœ‰ç»„ä»¶æµ‹è¯•é€šè¿‡!")
    return True


def test_training_step():
    """
    æµ‹è¯•è®­ç»ƒæ­¥éª¤
    """
    print("\nğŸ‹ï¸ æµ‹è¯•è®­ç»ƒæ­¥éª¤...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹
    model = EquivariantNet(
        hidden_dim=64,
        num_layers=2,
        num_radial_basis=32,
        cutoff_radius=5.0,
        max_neighbors=10
    ).to(device)
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    data = create_test_data(num_atoms=5, batch_size=2)
    
    # åˆ›å»ºå‡çš„ç›®æ ‡å€¼
    target_energy = torch.randn(2, device=device)
    target_forces = torch.randn(10, 3, device=device)
    
    try:
        # å‰å‘ä¼ æ’­
        pred_energy, pred_forces = model(data)
        
        # è®¡ç®—æŸå¤±
        energy_loss = nn.MSELoss()(pred_energy, target_energy)
        force_loss = nn.MSELoss()(pred_forces, target_forces)
        total_loss = energy_loss + force_loss
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()
        
        print(f"âœ… è®­ç»ƒæ­¥éª¤æˆåŠŸ!")
        print(f"   æ€»æŸå¤±: {total_loss.item():.6f}")
        print(f"   èƒ½é‡æŸå¤±: {energy_loss.item():.6f}")
        print(f"   åŠ›æŸå¤±: {force_loss.item():.6f}")
        
        return True
    except Exception as e:
        print(f"âŒ è®­ç»ƒæ­¥éª¤å¤±è´¥: {e}")
        return False


def test_batch_processing():
    """
    æµ‹è¯•æ‰¹å¤„ç†èƒ½åŠ›
    """
    print("\nğŸ“¦ æµ‹è¯•æ‰¹å¤„ç†...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    model = EquivariantNet(
        hidden_dim=64,
        num_layers=2,
        num_radial_basis=32,
        cutoff_radius=5.0,
        max_neighbors=10
    ).to(device)
    
    # æµ‹è¯•ä¸åŒæ‰¹å¤§å°
    batch_sizes = [1, 3, 5]
    atom_counts = [3, 7, 5]
    
    for batch_size, atoms_per_mol in zip(batch_sizes, atom_counts):
        try:
            data = create_test_data(num_atoms=atoms_per_mol, batch_size=batch_size)
            
            with torch.no_grad():
                energy, forces = model(data)
            
            expected_energy_shape = (batch_size,)
            expected_force_shape = (atoms_per_mol * batch_size, 3)
            
            assert energy.shape == expected_energy_shape, f"èƒ½é‡å½¢çŠ¶ä¸åŒ¹é…: {energy.shape} vs {expected_energy_shape}"
            assert forces.shape == expected_force_shape, f"åŠ›å½¢çŠ¶ä¸åŒ¹é…: {forces.shape} vs {expected_force_shape}"
            
            print(f"  âœ… æ‰¹å¤§å° {batch_size}, æ¯åˆ†å­ {atoms_per_mol} åŸå­: é€šè¿‡")
            
        except Exception as e:
            print(f"  âŒ æ‰¹å¤§å° {batch_size}, æ¯åˆ†å­ {atoms_per_mol} åŸå­: å¤±è´¥ - {e}")
            return False
    
    print("âœ… æ‰¹å¤„ç†æµ‹è¯•é€šè¿‡!")
    return True


def main():
    """
    ä¸»æµ‹è¯•å‡½æ•°
    """
    print("ğŸš€ å¼€å§‹æµ‹è¯•mlpotå®ç°...")
    print("=" * 50)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    test_results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_results.append(test_components())
    test_results.append(test_model_forward())
    test_results.append(test_equivariance())
    test_results.append(test_training_step())
    test_results.append(test_batch_processing())
    
    # æ€»ç»“ç»“æœ
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    
    passed = sum(test_results)
    total = len(test_results)
    
    print(f"é€šè¿‡: {passed}/{total}")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼mlpotå®ç°æ­£ç¡®ï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å®ç°")
    
    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
